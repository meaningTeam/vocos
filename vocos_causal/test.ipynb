{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "from pytorch_lightning import LightningDataModule\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from datalab import Dataset\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataConfig:\n",
    "    filelist_path: str\n",
    "    sampling_rate: int\n",
    "    num_samples: int\n",
    "    batch_size: int\n",
    "    num_workers: int\n",
    "\n",
    "\n",
    "class Collate:\n",
    "    \n",
    "    def __init__(self, train, num_samples, sampling_rate):\n",
    "        self.train = train\n",
    "        self.num_samples = num_samples\n",
    "        self.sampling_rate = sampling_rate\n",
    "        pass\n",
    "        \n",
    "    def __call__(self, batch):\n",
    "        print(batch)\n",
    "        y, sr = batch[\"audio\"].\n",
    "        if y.size(0) > 1:\n",
    "            # mix to mono\n",
    "            y = y.mean(dim=0, keepdim=True)\n",
    "        gain = np.random.uniform(-1, -6) if self.train else -3\n",
    "        y, _ = torchaudio.sox_effects.apply_effects_tensor(y, sr, [[\"norm\", f\"{gain:.2f}\"]])\n",
    "        if sr != self.sampling_rate:\n",
    "            y = torchaudio.functional.resample(y, orig_freq=sr, new_freq=self.sampling_rate)\n",
    "        if y.size(-1) < self.num_samples:\n",
    "            pad_length = self.num_samples - y.size(-1)\n",
    "            padding_tensor = y.repeat(1, 1 + pad_length // y.size(-1))\n",
    "            y = torch.cat((y, padding_tensor[:, :pad_length]), dim=1)\n",
    "        elif self.train:\n",
    "            start = np.random.randint(low=0, high=y.size(-1) - self.num_samples + 1)\n",
    "            y = y[:, start : start + self.num_samples]\n",
    "        else:\n",
    "            # During validation, take always the first segment for determinism\n",
    "            y = y[:, : self.num_samples]\n",
    "\n",
    "        return y[0]\n",
    "\n",
    "        \n",
    "class VocosDataModule(LightningDataModule):\n",
    "    def __init__(self, train_params: DataConfig, val_params: DataConfig):\n",
    "        super().__init__()\n",
    "        self.train_config = train_params\n",
    "        self.val_config = val_params\n",
    "\n",
    "    def _get_dataloder(self, cfg: DataConfig, train: bool):\n",
    "        dataset = VocosDataset(cfg, train=train)\n",
    "        dataloader = DataLoader(\n",
    "            dataset, batch_size=cfg.batch_size, num_workers=cfg.num_workers, shuffle=train, pin_memory=True,\n",
    "        )\n",
    "        return dataloader\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        dset = Dataset(\n",
    "            sources=[\"libritts-r-train-*\"],\n",
    "            fields=[\"audio\"],\n",
    "            max_batch_size=1\n",
    "        ).collate(\n",
    "           Collate()\n",
    "        )\n",
    "        cfg = self.train_config\n",
    "        return DataLoader(\n",
    "            dset, batch_size=cfg.batch_size, num_workers=cfg.num_workers, shuffle=False, pin_memory=True\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return self._get_dataloder(self.val_config, train=False)\n",
    "\n",
    "\n",
    "class VocosDataset(Dataset):\n",
    "    def __init__(self, cfg: DataConfig, train: bool):\n",
    "        with open(cfg.filelist_path) as f:\n",
    "            self.filelist = f.read().splitlines()\n",
    "        self.sampling_rate = cfg.sampling_rate\n",
    "        self.num_samples = cfg.num_samples\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.filelist)\n",
    "\n",
    "    def __getitem__(self, index: int) -> torch.Tensor:\n",
    "        audio_path = self.filelist[index]\n",
    "        y, sr = torchaudio.load(audio_path)\n",
    "        if y.size(0) > 1:\n",
    "            # mix to mono\n",
    "            y = y.mean(dim=0, keepdim=True)\n",
    "        gain = np.random.uniform(-1, -6) if self.train else -3\n",
    "        y, _ = torchaudio.sox_effects.apply_effects_tensor(y, sr, [[\"norm\", f\"{gain:.2f}\"]])\n",
    "        if sr != self.sampling_rate:\n",
    "            y = torchaudio.functional.resample(y, orig_freq=sr, new_freq=self.sampling_rate)\n",
    "        if y.size(-1) < self.num_samples:\n",
    "            pad_length = self.num_samples - y.size(-1)\n",
    "            padding_tensor = y.repeat(1, 1 + pad_length // y.size(-1))\n",
    "            y = torch.cat((y, padding_tensor[:, :pad_length]), dim=1)\n",
    "        elif self.train:\n",
    "            start = np.random.randint(low=0, high=y.size(-1) - self.num_samples + 1)\n",
    "            y = y[:, start : start + self.num_samples]\n",
    "        else:\n",
    "            # During validation, take always the first segment for determinism\n",
    "            y = y[:, : self.num_samples]\n",
    "\n",
    "        return y[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vojtech_meaning_team/vocos/env/lib/python3.11/site-packages/torch/cuda/__init__.py:716: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                              shard_id                      source  \\\n",
      "0   0  008ca261-0e23-4050-9737-db98d2073036  libritts-r-train-clean-100   \n",
      "\n",
      "                                               audio  \n",
      "0  ([[tensor(0.), tensor(0.), tensor(0.), tensor(...  \n",
      "tensor([0.0000e+00, 2.0742e-05, 2.0742e-05,  ..., 1.2463e-01, 1.2168e-01,\n",
      "        1.2276e-01])\n",
      "   id                              shard_id                      source  \\\n",
      "1   1  008ca261-0e23-4050-9737-db98d2073036  libritts-r-train-clean-100   \n",
      "\n",
      "                                               audio  \n",
      "1  ([[tensor(0.), tensor(0.), tensor(0.), tensor(...  \n",
      "          id                              shard_id  \\\n",
      "17232  17232  8351adc5-31d9-4457-bd64-5162a5c7e5a9   \n",
      "\n",
      "                           source  \\\n",
      "17232  libritts-r-train-clean-100   \n",
      "\n",
      "                                                   audio  \n",
      "17232  ([[tensor(0.), tensor(0.), tensor(0.), tensor(...  \n",
      "   id                              shard_id                      source  \\\n",
      "2   2  008ca261-0e23-4050-9737-db98d2073036  libritts-r-train-clean-100   \n",
      "\n",
      "                                               audio  \n",
      "2  ([[tensor(0.), tensor(0.), tensor(0.), tensor(...  \n",
      "tensor([0.0258, 0.0098, 0.0101,  ..., 0.0190, 0.0186, 0.0195])\n",
      "          id                              shard_id  \\\n",
      "17233  17233  8351adc5-31d9-4457-bd64-5162a5c7e5a9   \n",
      "\n",
      "                           source  \\\n",
      "17233  libritts-r-train-clean-100   \n",
      "\n",
      "                                                   audio  \n",
      "17233  ([[tensor(0.), tensor(0.), tensor(0.), tensor(...  \n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "dset = Dataset(\n",
    "            sources=[\"libritts-r-train-*\"],\n",
    "            fields=[\"audio\"],\n",
    "            shuffle=False,\n",
    "            max_batch_size=1\n",
    "        ).collate(\n",
    "           Collate(train=True, num_samples=16384, sampling_rate=24000)\n",
    "        )\n",
    "\n",
    "dloader = DataLoader(\n",
    "    dset, batch_size=None, num_workers=2, shuffle=False, pin_memory=True\n",
    ")\n",
    "for batch in islice(dloader, 2):\n",
    "    print(batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
